# -*- coding: utf-8 -*-
"""THE_BEST_CYCLIC_ALGORITHM!.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_QB-lJKKz_pgZTw5skmk9jcylL_XsKx3
"""

# from google.colab import drive
# drive.mount('/content/drive')

import torch
import torchvision
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np


from torch.utils.tensorboard import SummaryWriter
from torch.optim.lr_scheduler import CyclicLR
import torch.nn.functional as F

batch_size = 64
num_classes = 4
num_epochs = 20  # Total number of epochs
base_lr = 5e-4   # Minimum learning rate (adjusted for exploration)
max_lr = 1.2e-3  # Maximum learning rate (slightly above 0.0009)
step_size_up = 5

# Device will determine whether to run the training on GPU or CPU.
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize images to a standard size
    transforms.ToTensor(),          # Convert images to tensors
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize image data
])

train_dataset = torchvision.datasets.ImageFolder(root='MRI/Training', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

test_dataset = torchvision.datasets.ImageFolder(root='MRI/Testing', transform=transform)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

print('yea')
class ConvNet(nn.Module):
  def __init__(self, num_classes):
        super(ConvNet, self).__init__()

        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)

        # Pooling Layer
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        # Fully Connected Layers
        self.fc1 = nn.Linear(128 * 14 * 14, 512)  # Adjust dimensions if using a different input size
        self.fc2 = nn.Linear(512, num_classes)


        # Dropout
        self.dropout = nn.Dropout(0.5)


  def forward(self, x):
        # Apply Convolutional and Pooling layers
        x = self.pool(F.elu(self.conv1(x)))
        x = self.pool(F.elu(self.conv2(x)))
        x = self.pool(F.elu(self.conv3(x)))
        x = self.pool(F.elu(self.conv4(x)))

        # Flatten for fully connected layers
        x = x.view(-1, 128 * 14 * 14)

        # Fully connected layers with dropout
        x = F.elu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)

        return x

model = ConvNet(num_classes).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=base_lr)
scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size_up=step_size_up, mode='triangular')

total_step = len(train_loader)

writer = SummaryWriter()

def train():
    for epoch in range(num_epochs):
        # Training loop
        for i, (images, labels) in enumerate(train_loader):
            # Move tensors to the configured device
            images = images.to(device)
            labels = labels.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # Update the learning rate with the scheduler
            scheduler.step()

            # Log training loss and learning rate
            if (i + 1) % 10 == 0:
                writer.add_scalar('training_loss', loss.item(), epoch * total_step + i)
                writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch * total_step + i)

        # Save model checkpoint at the end of each epoch
        torch.save(model.state_dict(), f"checkpoints/ELU_CYCLE/model_epoch_{epoch + 1}.pth")

        # Print epoch stats
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0]["lr"]:.6f}')


# model.load_state_dict(torch.load("/content/drive/MyDrive/Colab Notebooks/checkpoints/ELU_CYCLE/model_epoch_20.pth"))
# # #replace X
# model.to(device)


def test():
    # Close the SummaryWriter
    writer.close()

    with torch.no_grad():
        for epoch in range(num_epochs):
            model.load_state_dict(torch.load(f"checkpoints/ELU_CYCLE/model_epoch_{epoch + 1}.pth"))
            model.to(device)
            print(f"Epoch: {epoch+1}")

            correct = 0  # Reset for each epoch
            total = 0    # Reset for each epoch

            for images, labels in test_loader:
                images = images.to(device)
                labels = labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

            print('Accuracy of the network on the {} test images: {} %'.format(len(test_loader.dataset), 100 * correct / total))

    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        print('Accuracy of the network on the {} test images: {} %'.format(len(test_loader.dataset), 100 * correct / total))



# Define your test dataset (replace with your actual test loader)
# Assuming test_loader is your DataLoader for the test set

# Define class labels
def confusion():
    class_labels = ["glioma_tumor", "meningioma_tumor", "no_tumor", "pituitary_tumor"]

    # Ensure the model is in evaluation mode
    model.eval()

    all_preds = []
    all_labels = []

    # Iterate through the test data
    with torch.no_grad():
        for images, labels in test_loader:  # Replace test_loader with your DataLoader
            images, labels = images.to(device), labels.to(device)

            # Get model predictions
            outputs = model(images)
            _, preds = torch.max(outputs, 1)

            # Store predictions and true labels
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # Generate the confusion matrix
    cm = confusion_matrix(all_labels, all_preds)

    # Display the confusion matrix
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)
    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')

    # Title for the confusion matrix plot
    plt.title("Confusion Matrix")
    plt.show()

    print(train_loader.dataset.class_to_idx)